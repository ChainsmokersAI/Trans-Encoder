{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94571daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "module_path=\"..\"\n",
    "sys.path.append(module_path)\n",
    "\n",
    "from distillation import distill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cc66933",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import transformers\n",
    "from transformers.utils import logging\n",
    "\n",
    "logging.set_verbosity(transformers.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105d6c0e",
   "metadata": {},
   "source": [
    "### Loop no.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfc75858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th Bi-Encoder\n",
      "-----\n",
      "[[1.         0.81180199]\n",
      " [0.81180199 1.        ]]\n",
      "SpearmanrResult(correlation=0.8009763763165447, pvalue=4.38233081262766e-309)\n",
      "=====\n",
      "0th Cross-Encoder\n",
      "-----\n",
      "[[1.         0.15960314]\n",
      " [0.15960314 1.        ]]\n",
      "SpearmanrResult(correlation=0.14341094701933937, pvalue=8.874086483411752e-08)\n",
      "\n",
      "Pseudo-Labeling..\n",
      "Done!\n",
      "\n",
      "Training..\n",
      "5749 data proceesed\n",
      "Done!\n",
      "\n",
      "1th (Newly Distilled) Cross-Encoder\n",
      "-----\n",
      "[[1.         0.82434503]\n",
      " [0.82434503 1.        ]]\n",
      "SpearmanrResult(correlation=0.830729034235989, pvalue=0.0)\n"
     ]
    }
   ],
   "source": [
    "# Loop 1: Bi-to-Cross Encoder Distillation\n",
    "\"\"\"\n",
    "direction: \"bi2cross\" or \"cross2bi\"\n",
    "path_dataset: path of dataset, default: STS Benchmark Train Set\n",
    "path_bi_model: path of distilled Bi-Encoder, if NOT set, initialize with 'base_bi_lm'\n",
    "path_cross_model: path of distilled Cross-Encoder, if NOT set, initialize with 'base_cross_lm'\n",
    "base_bi_lm: default: \"princeton-nlp/unsup-simcse-roberta-base\"\n",
    "base_cross_lm: default: \"roberta-base\"\n",
    "device_name: device for training, default: \"cpu\"\n",
    "\"\"\"\n",
    "distill(\n",
    "    direction=\"bi2cross\",\n",
    "    n_loop=1,\n",
    "    device_name=\"cuda:3\",\n",
    "    # Hyperparams for Training Model (Distillation)\n",
    "    hyperparams={\n",
    "        \"batch_size\": 16,\n",
    "        \"accum_steps\": 2,\n",
    "        \"lr\": 3e-5,\n",
    "        \"epochs\": 5,\n",
    "        # Training Loss: BCE or MSE\n",
    "        \"loss_func\": \"BCE\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ed55f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th Bi-Encoder\n",
      "-----\n",
      "[[1.         0.81180199]\n",
      " [0.81180199 1.        ]]\n",
      "SpearmanrResult(correlation=0.8009763763165447, pvalue=4.38233081262766e-309)\n",
      "=====\n",
      "1th Cross-Encoder\n",
      "-----\n",
      "[[1.         0.82434503]\n",
      " [0.82434503 1.        ]]\n",
      "SpearmanrResult(correlation=0.830729034235989, pvalue=0.0)\n",
      "\n",
      "Pseudo-Labeling..\n",
      "Done!\n",
      "\n",
      "Training..\n",
      "5749 data processed\n",
      "Done!\n",
      "\n",
      "1th (Newly Distilled) Bi-Encoder\n",
      "-----\n",
      "[[1.         0.81621777]\n",
      " [0.81621777 1.        ]]\n",
      "SpearmanrResult(correlation=0.8098011102455234, pvalue=3.44e-321)\n"
     ]
    }
   ],
   "source": [
    "# Loop 1: Cross-to-Bi Encoder Distillation\n",
    "distill(\n",
    "    direction=\"cross2bi\",\n",
    "    n_loop=1,\n",
    "    # Trained (Distilled) Cross-Encoder\n",
    "    path_cross_model=\"../model/cross-encoder_distilled_loop1_epoch5of5.pth\",\n",
    "    device_name=\"cuda:3\",\n",
    "    # Hyperparams for Training Model (Distillation)\n",
    "    hyperparams={\n",
    "        \"batch_size\": 16,\n",
    "        \"accum_steps\": 1,\n",
    "        \"lr\": 3e-7,\n",
    "        \"epochs\": 1,\n",
    "        # Training Loss: BCE or MSE\n",
    "        \"loss_func\": \"MSE\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022c7a03",
   "metadata": {},
   "source": [
    "### Loop no.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "960adb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th Bi-Encoder\n",
      "-----\n",
      "[[1.         0.81621777]\n",
      " [0.81621777 1.        ]]\n",
      "SpearmanrResult(correlation=0.8098011102455234, pvalue=3.44e-321)\n",
      "=====\n",
      "1th Cross-Encoder\n",
      "-----\n",
      "[[1.         0.82434503]\n",
      " [0.82434503 1.        ]]\n",
      "SpearmanrResult(correlation=0.830729034235989, pvalue=0.0)\n",
      "\n",
      "Pseudo-Labeling..\n",
      "Done!\n",
      "\n",
      "Training..\n",
      "5749 data proceesed\n",
      "Done!\n",
      "\n",
      "2th (Newly Distilled) Cross-Encoder\n",
      "-----\n",
      "[[1.         0.81966953]\n",
      " [0.81966953 1.        ]]\n",
      "SpearmanrResult(correlation=0.8344422038243441, pvalue=0.0)\n"
     ]
    }
   ],
   "source": [
    "# Loop 2: Bi-to-Cross Encoder Distillation\n",
    "distill(\n",
    "    direction=\"bi2cross\",\n",
    "    n_loop=2,\n",
    "    # Trained (Distilled) Bi-Encoder\n",
    "    path_bi_model=\"../model/bi-encoder_distilled_loop1_epoch1of1.pth\",\n",
    "    # Trained (Distilled) Cross-Encoder\n",
    "    path_cross_model=\"../model/cross-encoder_distilled_loop1_epoch5of5.pth\",\n",
    "    device_name=\"cuda:3\",\n",
    "    # Hyperparams for Training Model (Distillation)\n",
    "    hyperparams={\n",
    "        \"batch_size\": 16,\n",
    "        \"accum_steps\": 2,\n",
    "        \"lr\": 1e-5,\n",
    "        \"epochs\": 5,\n",
    "        # Training Loss: BCE or MSE\n",
    "        \"loss_func\": \"BCE\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbd431ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th Bi-Encoder\n",
      "-----\n",
      "[[1.         0.81621777]\n",
      " [0.81621777 1.        ]]\n",
      "SpearmanrResult(correlation=0.8098011102455234, pvalue=3.44e-321)\n",
      "=====\n",
      "2th Cross-Encoder\n",
      "-----\n",
      "[[1.         0.81966953]\n",
      " [0.81966953 1.        ]]\n",
      "SpearmanrResult(correlation=0.8344422038243441, pvalue=0.0)\n",
      "\n",
      "Pseudo-Labeling..\n",
      "Done!\n",
      "\n",
      "Training..\n",
      "5749 data processed\n",
      "Done!\n",
      "\n",
      "2th (Newly Distilled) Bi-Encoder\n",
      "-----\n",
      "[[1.         0.81584442]\n",
      " [0.81584442 1.        ]]\n",
      "SpearmanrResult(correlation=0.8101051454555238, pvalue=1.285e-321)\n"
     ]
    }
   ],
   "source": [
    "# Loop 2: Cross-to-Bi Encoder Distillation\n",
    "distill(\n",
    "    direction=\"cross2bi\",\n",
    "    n_loop=2,\n",
    "    # Trained (Distilled) Bi-Encoder\n",
    "    path_bi_model=\"../model/bi-encoder_distilled_loop1_epoch1of1.pth\",\n",
    "    # Trained (Distilled) Cross-Encoder\n",
    "    path_cross_model=\"../model/cross-encoder_distilled_loop2_epoch5of5.pth\",\n",
    "    device_name=\"cuda:3\",\n",
    "    # Hyperparams for Training Model (Distillation)\n",
    "    hyperparams={\n",
    "        \"batch_size\": 16,\n",
    "        \"accum_steps\": 1,\n",
    "        \"lr\": 3e-8,\n",
    "        \"epochs\": 1,\n",
    "        # Training Loss: BCE or MSE\n",
    "        \"loss_func\": \"MSE\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ed949f",
   "metadata": {},
   "source": [
    "### Loop no.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7843a1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2th Bi-Encoder\n",
      "-----\n",
      "[[1.         0.81584442]\n",
      " [0.81584442 1.        ]]\n",
      "SpearmanrResult(correlation=0.8101051454555238, pvalue=1.285e-321)\n",
      "=====\n",
      "2th Cross-Encoder\n",
      "-----\n",
      "[[1.         0.81966953]\n",
      " [0.81966953 1.        ]]\n",
      "SpearmanrResult(correlation=0.8344422038243441, pvalue=0.0)\n",
      "\n",
      "Pseudo-Labeling..\n",
      "Done!\n",
      "\n",
      "Training..\n",
      "5749 data proceesed\n",
      "Done!\n",
      "\n",
      "3th (Newly Distilled) Cross-Encoder\n",
      "-----\n",
      "[[1.         0.81990786]\n",
      " [0.81990786 1.        ]]\n",
      "SpearmanrResult(correlation=0.8356097036108407, pvalue=0.0)\n"
     ]
    }
   ],
   "source": [
    "# Loop 3: Bi-to-Cross Encoder Distillation\n",
    "distill(\n",
    "    direction=\"bi2cross\",\n",
    "    n_loop=3,\n",
    "    # Trained (Distilled) Bi-Encoder\n",
    "    path_bi_model=\"../model/bi-encoder_distilled_loop2_epoch1of1.pth\",\n",
    "    # Trained (Distilled) Cross-Encoder\n",
    "    path_cross_model=\"../model/cross-encoder_distilled_loop2_epoch5of5.pth\",\n",
    "    device_name=\"cuda:3\",\n",
    "    # Hyperparams for Training Model (Distillation)\n",
    "    hyperparams={\n",
    "        \"batch_size\": 16,\n",
    "        \"accum_steps\": 2,\n",
    "        \"lr\": 7e-7,\n",
    "        \"epochs\": 5,\n",
    "        # Training Loss: BCE or MSE\n",
    "        \"loss_func\": \"BCE\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09bfca9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2th Bi-Encoder\n",
      "-----\n",
      "[[1.         0.81584442]\n",
      " [0.81584442 1.        ]]\n",
      "SpearmanrResult(correlation=0.8101051454555238, pvalue=1.285e-321)\n",
      "=====\n",
      "3th Cross-Encoder\n",
      "-----\n",
      "[[1.         0.81990786]\n",
      " [0.81990786 1.        ]]\n",
      "SpearmanrResult(correlation=0.8356097036108407, pvalue=0.0)\n",
      "\n",
      "Pseudo-Labeling..\n",
      "Done!\n",
      "\n",
      "Training..\n",
      "5749 data processed\n",
      "Done!\n",
      "\n",
      "3th (Newly Distilled) Bi-Encoder\n",
      "-----\n",
      "[[1.         0.81561413]\n",
      " [0.81561413 1.        ]]\n",
      "SpearmanrResult(correlation=0.8102031033209242, pvalue=9.3e-322)\n"
     ]
    }
   ],
   "source": [
    "# Loop 3: Cross-to-Bi Encoder Distillation\n",
    "distill(\n",
    "    direction=\"cross2bi\",\n",
    "    n_loop=3,\n",
    "    # Trained (Distilled) Bi-Encoder\n",
    "    path_bi_model=\"../model/bi-encoder_distilled_loop2_epoch1of1.pth\",\n",
    "    # Trained (Distilled) Cross-Encoder\n",
    "    path_cross_model=\"../model/cross-encoder_distilled_loop3_epoch5of5.pth\",\n",
    "    device_name=\"cuda:3\",\n",
    "    # Hyperparams for Training Model (Distillation)\n",
    "    hyperparams={\n",
    "        \"batch_size\": 16,\n",
    "        \"accum_steps\": 1,\n",
    "        \"lr\": 1e-8,\n",
    "        \"epochs\": 1,\n",
    "        # Training Loss: BCE or MSE\n",
    "        \"loss_func\": \"MSE\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b4617d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
