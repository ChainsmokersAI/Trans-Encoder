{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5aaf3bd",
   "metadata": {},
   "source": [
    "### Load Bi-Encoder: Unsupervised SimCSE & Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47fdfde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "import numpy as np\n",
    "from scipy import spatial, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f62649b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded!\n"
     ]
    }
   ],
   "source": [
    "# Device: GPU\n",
    "device=torch.device(\"cuda:0\")\n",
    "\n",
    "# Checkpoint: Unsupervised SimCSE\n",
    "tokenizer_bi=AutoTokenizer.from_pretrained(\"princeton-nlp/unsup-simcse-roberta-base\")\n",
    "bi_enc=AutoModel.from_pretrained(\"princeton-nlp/unsup-simcse-roberta-base\").to(device)\n",
    "bi_enc.eval()\n",
    "print(\"Loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f4e0ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STS Benchmark Test Set\n",
    "with open(\"../dataset/stsbenchmark/sts-test.csv\", \"r\") as f:\n",
    "    data=f.read().split(\"\\n\")\n",
    "    data.remove(\"\")\n",
    "    f.close()\n",
    "    \n",
    "preds=[]\n",
    "labels=[]\n",
    "for _data in data:\n",
    "    label, sent0, sent1=_data.split(\"\\t\")[4:7]\n",
    "    labels.append(float(label))\n",
    "    \n",
    "    # Encode Sentence\n",
    "    enc0=tokenizer_bi.encode(sent0)\n",
    "    enc1=tokenizer_bi.encode(sent1)\n",
    "    \n",
    "    # Forward\n",
    "    cls0=bi_enc(torch.tensor([enc0]).to(device)).last_hidden_state[:,0,:]\n",
    "    cls1=bi_enc(torch.tensor([enc1]).to(device)).last_hidden_state[:,0,:]\n",
    "    \n",
    "    pred=1-spatial.distance.cosine(np.array(cls0.detach().cpu()), np.array(cls1.detach().cpu()))\n",
    "    preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87d181de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.81180198],\n",
       "       [0.81180198, 1.        ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(preds, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c21d86ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.8009763763165447, pvalue=4.38233081262766e-309)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.spearmanr(preds, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ab21dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21e192b5",
   "metadata": {},
   "source": [
    "### Create Pseudo-Labels using Bi-Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61a1f0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48202899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded!\n"
     ]
    }
   ],
   "source": [
    "# Device: GPU\n",
    "device=torch.device(\"cuda:0\")\n",
    "\n",
    "# Checkpoint: Unsupervised SimCSE\n",
    "tokenizer_bi=AutoTokenizer.from_pretrained(\"princeton-nlp/unsup-simcse-roberta-base\")\n",
    "bi_enc=AutoModel.from_pretrained(\"princeton-nlp/unsup-simcse-roberta-base\").to(device)\n",
    "bi_enc.eval()\n",
    "print(\"Loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcb5c79",
   "metadata": {},
   "source": [
    "### How to Make Sentence Pairs:\n",
    "### a. Same Pairs in STS-B Train Set (NOT Use Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a52629ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pseudo_label(dataset_path, tokenizer, model):\n",
    "    \"\"\"\n",
    "    Same Pairs in STS-B Train Set\n",
    "    \"\"\"\n",
    "    # Read Dataset\n",
    "    sents0=[]\n",
    "    sents1=[]\n",
    "    if \"stsbenchmark\" in dataset_path:\n",
    "        data=open(dataset_path).read().split(\"\\n\")\n",
    "        data.remove(\"\")\n",
    "        \n",
    "        # Parse Dataset\n",
    "        for _data in data:\n",
    "            sent0, sent1=_data.split(\"\\t\")[5:7]\n",
    "            \n",
    "            sents0.append(sent0)\n",
    "            sents1.append(sent1)\n",
    "            \n",
    "    # Make DataFrame\n",
    "    df=pd.DataFrame({\n",
    "        \"sent0\": sents0,\n",
    "        \"sent1\": sents1,\n",
    "    })\n",
    "    \n",
    "    # Pseudo-Labeling\n",
    "    pseudo_labels=[]\n",
    "    for idx in df.index:\n",
    "        row=df.loc[idx]\n",
    "        \n",
    "        # Encode Sentence\n",
    "        enc0=tokenizer.encode(row[\"sent0\"])\n",
    "        enc1=tokenizer.encode(row[\"sent1\"])\n",
    "        \n",
    "        # Forward\n",
    "        cls0=model(torch.tensor([enc0]).to(model.device)).last_hidden_state[:,0,:]\n",
    "        cls1=model(torch.tensor([enc1]).to(model.device)).last_hidden_state[:,0,:]\n",
    "        \n",
    "        pred=1-spatial.distance.cosine(np.array(cls0.detach().cpu()), np.array(cls1.detach().cpu()))\n",
    "        pseudo_labels.append(pred)\n",
    "        \n",
    "    # Append Pseudo-Label Column\n",
    "    df[\"pseudo_label\"]=pseudo_labels\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7c81036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent0</th>\n",
       "      <th>sent1</th>\n",
       "      <th>pseudo_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A plane is taking off.</td>\n",
       "      <td>An air plane is taking off.</td>\n",
       "      <td>0.982021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A man is playing a large flute.</td>\n",
       "      <td>A man is playing a flute.</td>\n",
       "      <td>0.969140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A man is spreading shreded cheese on a pizza.</td>\n",
       "      <td>A man is spreading shredded cheese on an uncoo...</td>\n",
       "      <td>0.920545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Three men are playing chess.</td>\n",
       "      <td>Two men are playing chess.</td>\n",
       "      <td>0.891384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A man is playing the cello.</td>\n",
       "      <td>A man seated is playing the cello.</td>\n",
       "      <td>0.910757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sent0  \\\n",
       "0                         A plane is taking off.   \n",
       "1                A man is playing a large flute.   \n",
       "2  A man is spreading shreded cheese on a pizza.   \n",
       "3                   Three men are playing chess.   \n",
       "4                    A man is playing the cello.   \n",
       "\n",
       "                                               sent1  pseudo_label  \n",
       "0                        An air plane is taking off.      0.982021  \n",
       "1                          A man is playing a flute.      0.969140  \n",
       "2  A man is spreading shredded cheese on an uncoo...      0.920545  \n",
       "3                         Two men are playing chess.      0.891384  \n",
       "4                 A man seated is playing the cello.      0.910757  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pseudo_label(\n",
    "    dataset_path=\"../dataset/stsbenchmark/sts-train.csv\",\n",
    "    tokenizer=tokenizer_bi,\n",
    "    model=bi_enc\n",
    ")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca6c2e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df[\"pseudo_label\"], bins=10, range=(0,1))\n",
    "plt.title(\"Distribution of Pseudo-Labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32cc120f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Dataset\n",
    "df.to_csv(\"../dataset/bi2cross-sts-train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a88c5a",
   "metadata": {},
   "source": [
    "### b. Random Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7d7c322",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pseudo_label(dataset_path, tokenizer, model):\n",
    "    \"\"\"\n",
    "    Random Pairs\n",
    "    \"\"\"\n",
    "    # Read All Sentences from Dataset\n",
    "    sents=[]\n",
    "    if \"stsbenchmark\" in dataset_path:\n",
    "        data=open(dataset_path).read().split(\"\\n\")\n",
    "        data.remove(\"\")\n",
    "        \n",
    "        for _data in data:\n",
    "            sents.extend(_data.split(\"\\t\")[5:7])\n",
    "            \n",
    "    # Random Pairing\n",
    "    sents0=[]\n",
    "    sents1=[]\n",
    "    while len(sents)>0:\n",
    "        sent0, sent1=sample(sents, 2)\n",
    "        \n",
    "        sents0.append(sent0)\n",
    "        sents1.append(sent1)\n",
    "        \n",
    "        sents.remove(sent0)\n",
    "        sents.remove(sent1)\n",
    "        \n",
    "    # Pseudo-Labeling\n",
    "    pseudo_labels=[]\n",
    "    for sent0, sent1 in zip(sents0, sents1):\n",
    "        # Encode Sentence\n",
    "        enc0=tokenizer.encode(sent0)\n",
    "        enc1=tokenizer.encode(sent1)\n",
    "        \n",
    "        # Forward\n",
    "        cls0=model(torch.tensor([enc0]).to(model.device)).last_hidden_state[:,0,:]\n",
    "        cls1=model(torch.tensor([enc1]).to(model.device)).last_hidden_state[:,0,:]\n",
    "        \n",
    "        pred=1-spatial.distance.cosine(np.array(cls0.detach().cpu()), np.array(cls1.detach().cpu()))\n",
    "        pseudo_labels.append(pred)\n",
    "        \n",
    "    # Make DataFrame\n",
    "    df=pd.DataFrame({\n",
    "        \"sent0\": sents0,\n",
    "        \"sent1\": sents1,\n",
    "        \"pseudo_label\": pseudo_labels\n",
    "    })\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62e87855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent0</th>\n",
       "      <th>sent1</th>\n",
       "      <th>pseudo_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malaysia to extradite Iranian for attack on Is...</td>\n",
       "      <td>A little bird floating in the water.</td>\n",
       "      <td>0.287990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>School bomb attack kills two in southern Thailand</td>\n",
       "      <td>A small child in a pink dress sits on a table.</td>\n",
       "      <td>0.263205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Garner said the self-proclaimed mayor of Baghd...</td>\n",
       "      <td>A woman is playing a flute.</td>\n",
       "      <td>0.271988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Syria launches ground assault in Aleppo</td>\n",
       "      <td>Since early May, the city has received 1,400 r...</td>\n",
       "      <td>0.270703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A man is slicing a potato.</td>\n",
       "      <td>Former CIA officer sentenced to 30 months in p...</td>\n",
       "      <td>0.262453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sent0  \\\n",
       "0  Malaysia to extradite Iranian for attack on Is...   \n",
       "1  School bomb attack kills two in southern Thailand   \n",
       "2  Garner said the self-proclaimed mayor of Baghd...   \n",
       "3            Syria launches ground assault in Aleppo   \n",
       "4                         A man is slicing a potato.   \n",
       "\n",
       "                                               sent1  pseudo_label  \n",
       "0               A little bird floating in the water.      0.287990  \n",
       "1     A small child in a pink dress sits on a table.      0.263205  \n",
       "2                        A woman is playing a flute.      0.271988  \n",
       "3  Since early May, the city has received 1,400 r...      0.270703  \n",
       "4  Former CIA officer sentenced to 30 months in p...      0.262453  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pseudo_label(\n",
    "    dataset_path=\"../dataset/stsbenchmark/sts-train.csv\",\n",
    "    tokenizer=tokenizer_bi,\n",
    "    model=bi_enc\n",
    ")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bfb0a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAWuUlEQVR4nO3debRlZX3m8e8jOCxlTpU0k5RD2bE0K2iXQC/TEReKgLbEdCSwVApCS2JAk0gnwSGN0diNnVYT2ikYqgEnwCGxEjGIqCFJC1IoMimhRIZiqmIQQdQI/vqP/ZYcinvrnlv31r1c3u9nrbPuOe/e5x32PfXsfd69765UFZKkPjxmvjsgSZo7hr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfZHkw0n+ZJbqekqSe5Ns1V5/Ncl/nY26W31fSLJituqbRrt/luT2JLfOddvjmO3tPGabRyb557l+r2bG0H+US3Jdkh8luSfJ95P8vyS/k+Tnv/uq+p2qeueYdb14U+tU1Q1VtU1VPTALfX97ko9tVP9BVXX6TOueZj+eAhwPLKuqfzfB8v2S/Kzt7O5JcnWSo+ayjzMx0XbWo5eh34f/XFXbAnsCJwF/DJw6240k2Xq263yEeApwR1Wt28Q6N1fVNsB2DNv3I0mWzUnvpGkw9DtSVXdX1SrgN4EVSZ4DkOS0JH/Wni9K8vftW8GdSf4pyWOSfJQh/P6uHdH+UZIlSSrJ0UluAL48Uja6A3h6kq8n+UGSzyXZqbW1X5K1o33c8G0iyYHAW4DfbO19qy3/+TRG69fbklyfZF2SM5Js35Zt6MeKJDe0qZm3TrZtkmzf3r++1fe2Vv+LgfOAXVs/TptiG1dV/S1wF7AsyTOS/GOSu1sfzhpp8xeTnNe289VJDh1Z9pDpmo2nQ5K8JMl3Wr3vBzKybNLtMl1JTkjy3fYN5qokr3z4Knl/68d3kuw/smD7JKcmuSXJTRmmyLaaoI0keV/r6w+SXL7hs6nZZ+h3qKq+DqwF/tMEi49vyxYDOzMEb1XVa4EbGL41bFNV/2vkPS8EngW8dJImjwB+C9gFuB84eYw+/gPwP4CzWnu/PMFqR7bHi4CnAdsA799onV8B/j2wP/Dfkzxrkib/D7B9q+eFrc9HVdWXgINoR/JVdeSm+t0C95XADsDlwDuBLwI7Aru3dkjyJIadySeAJwOHAR8c59tBkkXAZ4G3AYuA7wIvGFnlSKbeLuP6LsPnZHvgT4GPJdllZPk+bZ1FwInAZzfs1IHTGH7fzwCeCxwATHTe4QDgV4FntnYOBe7YzP5qCoZ+v24Gdpqg/KcM4bxnVf20qv6ppr5B09ur6odV9aNJln+0qq6oqh8CfwIcOtER32Z4NfDeqrq2qu4F3gwcttG3jD+tqh9V1beAbwEP23m0vhwGvLmq7qmq64D3AK+dRl92TfJ94HaG8HttVV3NsD33BHatqh9X1Yaj9ZcD11XV/62q+6vqm8BngFeN0dbBwJVV9emq+inwF8DoCeZxtstYqupTVXVzVf2sqs4CrgH2HlllHfAX7bNyFnA18LIkO7d+/n77bKwD3sewnTf2U2Bb4BeBVNW3q+qW6fZV4zH0+7UbcOcE5X8OrAG+mOTaJCeMUdeN01h+PfBYhiPDmdq11Tda99YM31A2GA3D+xiOeje2qPVp47p2m0Zfbq6qHapqp6raq6rObOV/xDD18vUkVyb5rVa+J7BPm0b7ftthvBp42IniCezKyDZtO+UbN1o+4XZJ8uo2TXVvki9M1VCSI5JcOtLH5/DQ391NGx0UXN/a35Nhm94y8t6/YvhW8xBV9WWGbyIfANYlOSXJdlP1TZvH0O9QkuczBNrDLplrR7rHV9XTgFcAbxqZp53siH+qbwJ7jDx/CsOR3e3AD4EnjvRrK4ZppXHrvZkhXEbrvh+4bYr3bex2HjwiH63rpmnW8zBVdWtVva6qdgV+m2EK5xkMIf2PbUex4bFNVb2+vfUh24aH7gxuYWSbJgkP3caTbpeq+nhrZ5uqOmhTfU+yJ/AR4DjgF6pqB+AKRs4fALu19kfburmN7yfAopHxbVdVz56orao6uar+A7CMYZrnDzfVN20+Q78jSbZL8nLgTOBjVXX5BOu8vJ18DHA38ADws7b4NoY54ul6TZJlSZ4IvAP4dLuk81+BJyR5WZLHMsxRP37kfbcBSzJyeelGPgn8QZKnJtmGB88B3D+dzrW+nA28K8m2LezeBMz4MsYkr0qye3t5F8OO7GfA3wPPTPLaJI9tj+ePnHO4FPj1JE9sO4mjR6r9PPDsJL/epmzeyEN3CpuzXR6T5Akjj8cDT2r9Xd/GchTDkf6oJwNvbP1/FcO5nXPa9MwXgfe0z91jkjw9yQsn2EbPT7JP+wz8EPgxD37mNMsM/T78XZJ7GI6+3gq8F5jsOvKlwJeAe4GvAR+sqq+0Zf8TeFv7uv7fptH+RxlO6t0KPIEhpKiqu4HfBf6a4aj6hwwnkTf4VPt5R5JvTFDvylb3BcD3GMLiDdPo16g3tPavZfgG9IlW/0w9H7goyb3AKuD32lz7PQwnMA9jODK+FXg3D+703gf8G8OO73Tg4xsqrKrbGeb+T2I44bkU+JeRNjdnuxwO/Gjk8d2quorh3MbXWj9+aaN2AC5q7d8OvAv4jaracBL2COBxwFUMO7xPM5wv2th2DN8o7mKYHrqDYZpRW0D8T1QkqR8e6UtSRwx9SeqIoS9JHTH0Jakjj+gbZC1atKiWLFky392QpAXlkksuub2qFk+0bMrQT7IHcAbDXzkWcEpV/WWStwOvo13DC7ylqs5p73kzw3XFDwBvrKpzW/mBwF8CWwF/XVUnbartJUuWsHr16qlHKEn6uSTXT7ZsnCP9+4Hjq+obSbYFLklyXlv2vqr63xs1tozh2uNnM/w59peSPLMt/gDwEoZrsS9OsqpdCyxJmgNThn77y7pb2vN7knybTd+T5BDgzKr6CfC9JGt48AZNa6rqWoAkZ7Z1DX1JmiPTOpGbZAnDLVIvakXHJbksycokO7ay3XjozZ/WtrLJyjdu45gkq5OsXr9+/caLJUkzMHbot3t4fIbhVqk/AD4EPB3Yi+GbwHtmo0NVdUpVLa+q5YsXT3geQpK0mca6eqfdCOkzwMer6rMAVXXbyPKPMNxACoZ7qIze8W93Hrxb4WTlkqQ5MOWRfrvb4qnAt6vqvSPlozdOeiXDLVdhuKnUYUken+SpDDdj+jpwMbC03fnvcQwne1fNzjAkSeMY50j/BQz/g9DlSS5tZW8BDk+yF8NlnNcx3CucqroyydkMJ2jvB45tt64lyXHAuQyXbK6sqitnbSSSpCk9ou+yuXz58vI6fUmaniSXVNXyiZZ5GwZJ6sgj+jYMmr4lJ3x+Xtq97qSXzUu7kqbH0NescGcjLQxO70hSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1JEpQz/JHkm+kuSqJFcm+b1WvlOS85Jc037u2MqT5OQka5JcluR5I3WtaOtfk2TFlhuWJGki4xzp3w8cX1XLgH2BY5MsA04Azq+qpcD57TXAQcDS9jgG+BAMOwngRGAfYG/gxA07CknS3Jgy9Kvqlqr6Rnt+D/BtYDfgEOD0ttrpwK+154cAZ9TgQmCHJLsALwXOq6o7q+ou4DzgwNkcjCRp06Y1p59kCfBc4CJg56q6pS26Fdi5Pd8NuHHkbWtb2WTlG7dxTJLVSVavX79+Ot2TJE1h7NBPsg3wGeD3q+oHo8uqqoCajQ5V1SlVtbyqli9evHg2qpQkNWOFfpLHMgT+x6vqs634tjZtQ/u5rpXfBOwx8vbdW9lk5ZKkOTLO1TsBTgW+XVXvHVm0CthwBc4K4HMj5Ue0q3j2Be5u00DnAgck2bGdwD2glUmS5sjWY6zzAuC1wOVJLm1lbwFOAs5OcjRwPXBoW3YOcDCwBrgPOAqgqu5M8k7g4rbeO6rqztkYhCRpPFOGflX9M5BJFu8/wfoFHDtJXSuBldPpoCRp9vgXuZLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1JEpQz/JyiTrklwxUvb2JDclubQ9Dh5Z9uYka5JcneSlI+UHtrI1SU6Y/aFIkqYyzpH+acCBE5S/r6r2ao9zAJIsAw4Dnt3e88EkWyXZCvgAcBCwDDi8rStJmkNbT7VCVV2QZMmY9R0CnFlVPwG+l2QNsHdbtqaqrgVIcmZb96rpd1mStLlmMqd/XJLL2vTPjq1sN+DGkXXWtrLJyiVJc2hzQ/9DwNOBvYBbgPfMVoeSHJNkdZLV69evn61qJUlsZuhX1W1V9UBV/Qz4CA9O4dwE7DGy6u6tbLLyieo+paqWV9XyxYsXb073JEmT2KzQT7LLyMtXAhuu7FkFHJbk8UmeCiwFvg5cDCxN8tQkj2M42btq87stSdocU57ITfJJYD9gUZK1wInAfkn2Agq4DvhtgKq6MsnZDCdo7weOraoHWj3HAecCWwErq+rK2R6MJGnTxrl65/AJik/dxPrvAt41Qfk5wDnT6p0kaVb5F7mS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOjJl6CdZmWRdkitGynZKcl6Sa9rPHVt5kpycZE2Sy5I8b+Q9K9r61yRZsWWGI0nalHGO9E8DDtyo7ATg/KpaCpzfXgMcBCxtj2OAD8GwkwBOBPYB9gZO3LCjkCTNnSlDv6ouAO7cqPgQ4PT2/HTg10bKz6jBhcAOSXYBXgqcV1V3VtVdwHk8fEciSdrCNndOf+equqU9vxXYuT3fDbhxZL21rWyy8odJckyS1UlWr1+/fjO7J0mayIxP5FZVATULfdlQ3ylVtbyqli9evHi2qpUksfmhf1ubtqH9XNfKbwL2GFlv91Y2WbkkaQ5tbuivAjZcgbMC+NxI+RHtKp59gbvbNNC5wAFJdmwncA9oZZKkObT1VCsk+SSwH7AoyVqGq3BOAs5OcjRwPXBoW/0c4GBgDXAfcBRAVd2Z5J3AxW29d1TVxieHJUlb2JShX1WHT7Jo/wnWLeDYSepZCaycVu8kSbPKv8iVpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1JEZhX6S65JcnuTSJKtb2U5JzktyTfu5YytPkpOTrElyWZLnzcYAJEnjm40j/RdV1V5Vtby9PgE4v6qWAue31wAHAUvb4xjgQ7PQtiRpGrbeAnUeAuzXnp8OfBX441Z+RlUVcGGSHZLsUlW3bIE+qBNLTvj8vLV93Ukvm7e2pc010yP9Ar6Y5JIkx7SynUeC/FZg5/Z8N+DGkfeubWUPkeSYJKuTrF6/fv0MuydJGjXTI/1fqaqbkjwZOC/Jd0YXVlUlqelUWFWnAKcALF++fFrvlSRt2oyO9KvqpvZzHfA3wN7AbUl2AWg/17XVbwL2GHn77q1MkjRHNjv0kzwpybYbngMHAFcAq4AVbbUVwOfa81XAEe0qnn2Bu53Pl6S5NZPpnZ2Bv0myoZ5PVNU/JLkYODvJ0cD1wKFt/XOAg4E1wH3AUTNoW5K0GTY79KvqWuCXJyi/A9h/gvICjt3c9iRJM+df5EpSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI1viv0vs3nz+F36StCke6UtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOuJ/oiJtpvn6z3KuO+ll89KuHh080pekjhj6ktQRQ1+SOmLoS1JH5jz0kxyY5Ooka5KcMNftS1LP5vTqnSRbAR8AXgKsBS5OsqqqrprLfkgL2XxdNQReOfRoMNdH+nsDa6rq2qr6N+BM4JA57oMkdWuur9PfDbhx5PVaYJ/RFZIcAxzTXt6b5OoZtLcIuH0G71+Iehtzb+OFeRxz3j0frQL+nqdrz8kWPOL+OKuqTgFOmY26kqyuquWzUddC0duYexsvOOZebKkxz/X0zk3AHiOvd29lkqQ5MNehfzGwNMlTkzwOOAxYNcd9kKRuzen0TlXdn+Q44FxgK2BlVV25BZuclWmiBaa3Mfc2XnDMvdgiY05VbYl6JUmPQP5FriR1xNCXpI4s+NCf6rYOSR6f5Ky2/KIkS+ahm7NqjDG/KclVSS5Lcn6SSa/ZXSjGvX1Hkv+SpJIs+Mv7xhlzkkPb7/rKJJ+Y6z7OtjE+209J8pUk32yf74Pno5+zJcnKJOuSXDHJ8iQ5uW2Py5I8b8aNVtWCfTCcDP4u8DTgccC3gGUbrfO7wIfb88OAs+a733Mw5hcBT2zPX9/DmNt62wIXABcCy+e733Pwe14KfBPYsb1+8nz3ew7GfArw+vZ8GXDdfPd7hmP+VeB5wBWTLD8Y+AIQYF/gopm2udCP9Me5rcMhwOnt+aeB/ZNkDvs426Ycc1V9paruay8vZPh7iIVs3Nt3vBN4N/DjuezcFjLOmF8HfKCq7gKoqnVz3MfZNs6YC9iuPd8euHkO+zfrquoC4M5NrHIIcEYNLgR2SLLLTNpc6KE/0W0ddptsnaq6H7gb+IU56d2WMc6YRx3NcKSwkE055va1d4+qmr+7kc2ucX7PzwSemeRfklyY5MA5692WMc6Y3w68Jsla4BzgDXPTtXkz3X/vU3rE3YZBsyfJa4DlwAvnuy9bUpLHAO8Fjpznrsy1rRmmePZj+DZ3QZJfqqrvz2entrDDgdOq6j1J/iPw0STPqaqfzXfHFoqFfqQ/zm0dfr5Okq0ZvhLeMSe92zLGupVFkhcDbwVeUVU/maO+bSlTjXlb4DnAV5NcxzD3uWqBn8wd5/e8FlhVVT+tqu8B/8qwE1ioxhnz0cDZAFX1NeAJDDcme7Sa9VvXLPTQH+e2DquAFe35bwBfrnaGZIGacsxJngv8FUPgL/R5XphizFV1d1UtqqolVbWE4TzGK6pq9fx0d1aM89n+W4ajfJIsYpjuuXYO+zjbxhnzDcD+AEmexRD66+e0l3NrFXBEu4pnX+DuqrplJhUu6OmdmuS2DkneAayuqlXAqQxfAdcwnDA5bP56PHNjjvnPgW2AT7Vz1jdU1SvmrdMzNOaYH1XGHPO5wAFJrgIeAP6wqhbst9gxx3w88JEkf8BwUvfIhXwQl+STDDvuRe08xYnAYwGq6sMM5y0OBtYA9wFHzbjNBby9JEnTtNCndyRJ02DoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI78f2po61MTdM5PAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df[\"pseudo_label\"], bins=10, range=(0,1))\n",
    "plt.title(\"Distribution of Pseudo-Labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1c360f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Dataset\n",
    "df.to_csv(\"../dataset/bi2cross-random-train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f465cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce27a495",
   "metadata": {},
   "source": [
    "### Train Cross-Encoder with Pseudo-Labels & Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3503803c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.cuda.amp as amp\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "import numpy as np\n",
    "from scipy import spatial, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1efc91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device: GPU\n",
    "device=torch.device(\"cuda:0\")\n",
    "\n",
    "# Hyperparams\n",
    "max_sent_len=256\n",
    "batch_size=16\n",
    "accum_steps=1\n",
    "lr=5e-5\n",
    "epochs=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c26dfd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PseudoLabelDataset(Dataset):\n",
    "    def __init__(self, path, tokenizer):\n",
    "        self.data=[]\n",
    "        self.label=[]\n",
    "        \n",
    "        # Read Dataset\n",
    "        df=pd.read_csv(path)\n",
    "        \n",
    "        for idx in df.index:\n",
    "            row=df.loc[idx]\n",
    "            \n",
    "            # Encode Sentence\n",
    "            enc0=tokenizer.encode(row[\"sent0\"], truncation=True, max_length=max_sent_len)\n",
    "            enc1=tokenizer.encode(row[\"sent1\"], truncation=True, max_length=max_sent_len)\n",
    "            \n",
    "            # Append Data\n",
    "            self.data.append(enc0[:-1]+[tokenizer.sep_token_id]+enc1[1:])\n",
    "            self.label.append(float(row[\"pseudo_label\"]))\n",
    "            \n",
    "        print(len(self.data), \"data\")\n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.label[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67f20f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_collate_fn(tokenizer):\n",
    "    def collate_fn(batch):\n",
    "        max_seq_len=0\n",
    "        for data, _ in batch:\n",
    "            if len(data)>max_seq_len: max_seq_len=len(data)\n",
    "\n",
    "        batch_data=[]\n",
    "        batch_label=[]\n",
    "        for data, label in batch:\n",
    "            data.extend([tokenizer.pad_token_id]*(max_seq_len-len(data)))\n",
    "            batch_data.append(data)\n",
    "\n",
    "            batch_label.append(label)\n",
    "\n",
    "        return torch.tensor(batch_data), torch.tensor(batch_label)\n",
    "    \n",
    "    return collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa42bcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEncoder(nn.Module):\n",
    "    def __init__(self, pretrained):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Pre-Trained LM\n",
    "        self.pretrained=pretrained\n",
    "        # Pooling Layer: MLP\n",
    "        self.pooler=nn.Linear(pretrained.config.hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x=self.pretrained(x)\n",
    "        cls=x.last_hidden_state[:,0,:]\n",
    "        return self.pooler(cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e048bbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cross_encoder_with_pseudo_labels(pseudo_label_path, loss_func):\n",
    "    \"\"\"\n",
    "    Bi-Encoder -> Cross-Encoder Distillation\n",
    "    \"\"\"\n",
    "    # Pre-Trained Tokenizer\n",
    "    tokenizer=AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "    # Pseudo-Labeled Dataset\n",
    "    dataset_train=PseudoLabelDataset(path=pseudo_label_path, tokenizer=tokenizer)\n",
    "    dataloader_train=DataLoader(\n",
    "        dataset_train,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        collate_fn=get_collate_fn(tokenizer=tokenizer)\n",
    "    )\n",
    "    \n",
    "    # Pre-Trained LM\n",
    "    pretrained=AutoModel.from_pretrained(\"roberta-base\").to(device)\n",
    "    # Model: Cross-Encoder\n",
    "    model=CrossEncoder(pretrained=pretrained).to(device)\n",
    "    model.train()\n",
    "    \n",
    "    # Loss: MSE\n",
    "    if loss_func==\"MSE\":\n",
    "        train_loss=nn.MSELoss()\n",
    "    # Loss: BCE\n",
    "    elif loss_func==\"BCE\":\n",
    "        train_loss=nn.BCEWithLogitsLoss()\n",
    "        \n",
    "    # Optimizer, Scheduler\n",
    "    optimizer=AdamW(model.parameters(), lr=lr)\n",
    "    scheduler=get_linear_schedule_with_warmup(\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=int(0.05*epochs*len(dataset_train)/(accum_steps*batch_size)),\n",
    "        num_training_steps=int(epochs*len(dataset_train)/(accum_steps*batch_size))\n",
    "    )\n",
    "\n",
    "    # Mixed Precision: GradScaler\n",
    "    scaler=amp.GradScaler()\n",
    "\n",
    "    # Tensorboard\n",
    "    writer=SummaryWriter()\n",
    "\n",
    "    step_global=0\n",
    "    for epoch in range(epochs):\n",
    "        _loss=0\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        for step, (data, label) in enumerate(dataloader_train):\n",
    "            # Load Data, Label\n",
    "            data=data.to(device)\n",
    "            label=label.to(device)\n",
    "\n",
    "            # Forward\n",
    "            with amp.autocast():\n",
    "                pred=model(data)\n",
    "                loss=train_loss(pred, label.unsqueeze(-1))/accum_steps\n",
    "            # Backward\n",
    "            scaler.scale(loss).backward()\n",
    "            _loss+=loss.item()\n",
    "\n",
    "            # Step\n",
    "            if (step+1)%accum_steps==0:\n",
    "                step_global+=1\n",
    "\n",
    "                # Tensorboard\n",
    "                writer.add_scalar(\n",
    "                    f'loss_train/Cross-Encoder-Distilled_batch{int(accum_steps*batch_size)}_lr{lr}_epochs{epochs}',\n",
    "                    _loss,\n",
    "                    step_global\n",
    "                )\n",
    "                _loss=0\n",
    "\n",
    "                # Optimizer, Scheduler\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "        # Save Model\n",
    "        model.to(torch.device(\"cpu\"))\n",
    "        torch.save(\n",
    "            model,\n",
    "            f'../model/Cross-Encoder-Distilled_batch{int(accum_steps*batch_size)}_lr{lr}_epoch{epoch+1}of{epochs}'\n",
    "        )\n",
    "        model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b671b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_distilled_cross_encoder(model_path):\n",
    "    # Pre-Trained Tokenizer\n",
    "    tokenizer=AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "    # Load Trained Model: Cross-Encoder\n",
    "    model=torch.load(model_path).to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # STS Benchmark Test Set\n",
    "    with open(\"../dataset/stsbenchmark/sts-test.csv\", \"r\") as f:\n",
    "        stsb_test=f.read()\n",
    "        f.close()\n",
    "\n",
    "    preds=[]\n",
    "    labels=[]\n",
    "    for data in stsb_test.split(\"\\n\")[:-1]:\n",
    "        label, sent0, sent1=data.split(\"\\t\")[4:7]\n",
    "        labels.append(float(label))\n",
    "\n",
    "        # Encode Sentence\n",
    "        enc0=tokenizer.encode(sent0)\n",
    "        enc1=tokenizer.encode(sent1)\n",
    "\n",
    "        # Forward\n",
    "        input_=torch.tensor([enc0[:-1]+[tokenizer.sep_token_id]+enc1[1:]])\n",
    "        pred=model(input_.to(device))\n",
    "\n",
    "        preds.append(pred[0].item())\n",
    "        \n",
    "    print(np.corrcoef(preds, labels))\n",
    "    print(stats.spearmanr(preds, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19229c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5749 data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/opt/conda/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    }
   ],
   "source": [
    "# Case a. Same Pairs in STS-B Train Set\n",
    "train_cross_encoder_with_pseudo_labels(pseudo_label_path=\"../dataset/bi2cross-sts-train.csv\", loss_func=\"BCE\")\n",
    "\n",
    "# Case b. Random Pairs\n",
    "# train_cross_encoder_with_pseudo_labels(pseudo_label_path=\"../dataset/bi2cross-random-train.csv\", loss_func=\"BCE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72bcb213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.81972359]\n",
      " [0.81972359 1.        ]]\n",
      "SpearmanrResult(correlation=0.8225849566372455, pvalue=0.0)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "evaluate_distilled_cross_encoder(model_path=\"../model/Cross-Encoder-Distilled_batch16_lr5e-05_epoch4of5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8163a71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
